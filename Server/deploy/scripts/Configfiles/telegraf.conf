# Configuration for telegraf agent
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  omit_hostname = false

###############################################################################
#                                  OUTPUTS                                    #
###############################################################################

## FOR NATS
#[[outputs.nats]]
# servers = ["nats://x.x.x.x:4222"]
#  subject = "telegraf"
#  ssl_ca = "ca.pem"
#  ssl_cert = "cert.pem"
#  ssl_key = "key.pem"
#  insecure_skip_verify = false
#  data_format = "influx"

[[outputs.influxdb]]
  urls = ["http://influxdb:8086"]
  database = "telegraf"
  retention_policy = ""
  write_consistency = "any"
  timeout = "5s"
  username = "root"
  password = "root"
  precision = "s"
###############################################################################
#                                  PLUGINS                                    #
###############################################################################



[[inputs.cpu]]
  percpu = false
  totalcpu = true
  fielddrop = ["time_*"]

[[inputs.diskio]]
  skip_serial_number = true

[[inputs.disk]]
# interval = "%INTERVAL_DISK%"

[[inputs.mem]]

# Get the number of processes and group them by status
[[inputs.processes]]

# Read metrics about swap memory usage
[[inputs.swap]]

[[inputs.docker]]
#   endpoint = "ENV"
   endpoint = "unix:///var/run/docker.sock"
   container_names = []
   timeout = "5s"
  ## docker labels to include and exclude as tags.  Globs accepted.
  ## Note that an empty array for both will include all labels as tags
  docker_label_include = []
  docker_label_exclude = []

# Get kernel statistics from /proc/stat
[[inputs.kernel]]

[[inputs.system]]
  [inputs.system.tags]
    n_cpus = "%N_CPUS%"
	
[[inputs.net]]
  interfaces = ["eth0"]
  [inputs.net.tagdrop]
  interface = ["all"]

[[inputs.net_response]]
  protocol = "tcp"
  address = ":80"

[[inputs.net_response]]
  protocol = "tcp"
  address = ":3000"

[[inputs.net_response]]
  protocol = "tcp"
  address = ":8086"

  tagexclude = ["server"]


# Azure Event Hubs service input plugin
[[inputs.eventhub_consumer]]
  ## The default behavior is to create a new Event Hub client from environment variables.
  ## This requires one of the following sets of environment variables to be set:
  ##
  ## 1) Expected Environment Variables:
  ##    - "EVENTHUB_NAMESPACE"
  ##    - "EVENTHUB_NAME"
  ##    - "EVENTHUB_CONNECTION_STRING"
  ##
  ## 2) Expected Environment Variables:
  ##    - "EVENTHUB_NAMESPACE"
  ##    - "EVENTHUB_NAME"
  ##    - "EVENTHUB_KEY_NAME"
  ##    - "EVENTHUB_KEY_VALUE"

  ## Uncommenting the option below will create an Event Hub client based solely on the connection string.
  ## This can either be the associated environment variable or hard coded directly.
  # connection_string = "HostName=BlueRobotMessageBroker.azure-devices.net;SharedAccessKeyName=iothubowner;SharedAccessKey=y4c8Gdwe8mrUNxrslqfHXEfuFsMuw8AqRS6xoa6HJhA="

  ## Set persistence directory to a valid folder to use a file persister instead of an in-memory persister
  # persistence_dir = ""

  ## Change the default consumer group
  consumer_group = "$Default"

  ## By default the event hub receives all messages present on the broker, alternative modes can be set below.
  ## The timestamp should be in https://github.com/toml-lang/toml#offset-date-time format (RFC 3339).
  ## The 3 options below only apply if no valid persister is read from memory or file (e.g. first run).
  # from_timestamp = 2020-04-24T22:05:00Z
  # latest = true

  ## Set a custom prefetch count for the receiver(s)
  prefetch_count = 1000

  ## Add an epoch to the receiver(s)
  # epoch = 0

  ## Change to set a custom user agent, "telegraf" is used by default
  # user_agent = "telegraf"

  ## To consume from a specific partition, set the partition_ids option.
  ## An empty array will result in receiving from all partitions.
   partition_ids = ["0","1"]
  #partition_ids = []

  ## Max undelivered messages
  # max_undelivered_messages = 1000

  ## Set either option below to true to use a system property as timestamp.
  ## You have the choice between EnqueuedTime and IoTHubEnqueuedTime.
  ## It is recommended to use this setting when the data itself has no timestamp.
  enqueued_time_as_ts = false
  iot_hub_enqueued_time_as_ts = false

  ## Tags or fields to create from keys present in the application property bag.
  ## These could for example be set by message enrichments in Azure IoT Hub.
  application_property_tags = ["IoTHubName","UpdateLatencySeconds" ]
  # application_property_fields = []

  ## Tag or field name to use for metadata
  ## By default all metadata is disabled
  # sequence_number_field = "SequenceNumber"
  # enqueued_time_field = "EnqueuedTime"
  # offset_field = "Offset"
  # partition_id_tag = "PartitionID"
  # partition_key_tag = "PartitionKey"
  iot_hub_device_connection_id_tag = "IoTHubDeviceConnectionID"
  # iot_hub_auth_generation_id_tag = "IoTHubAuthGenerationID"
  # iot_hub_connection_auth_method_tag = "IoTHubConnectionAuthMethod"
  iot_hub_connection_module_id_tag = "IoTHubConnectionModuleID"
  # iot_hub_enqueued_time_field = "IoTHubEnqueuedTime"

  ## Data format to consume.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
   #data_format = "influx"

# {
#   "body": {
#     "temperature": 21.5
#   },
#   "applicationProperties": {
#     "IoTHubName": "bluerobotmessagebroker",
#     "UpdateLatencySeconds": "$twin.properties.reported.updateLatencySeconds"
#   }
# }


# {
#     "a": 5,
#     "b": {
#         "c": 6,
#         "my_field": "description"
#     },
#     "my_tag_1": "foo",
#     "name": "my_json"
# }
# Output:

# my_json,my_tag_1=foo a=5,b_c=6,b_my_field="description"


  ## Time key is the key containing the time that should be used to create the
  ## metric.
  json_time_key = "timestamp"
  json_time_format = "unix_ms"

  ## Time format is the time layout that should be used to interprete the json_time_key.
  ## The time must be `unix`, `unix_ms`, `unix_us`, `unix_ns`, or a time in the
  ## "reference time".  To define a different format, arrange the values from
  ## the "reference time" in the example to match the format you will be
  ## using.  For more information on the "reference time", visit
  ## https://golang.org/pkg/time/#Time.Format
  ##   ex: json_time_format = "Mon Jan 2 15:04:05 -0700 MST 2006"
  ##       json_time_format = "2006-01-02T15:04:05Z07:00"
  ##       json_time_format = "01/02/2006 15:04:05"
  ##       json_time_format = "unix"
  ##       json_time_format = "unix_ms"
  #json_time_format = "2006-01-02T15:04:05.999999+07:00Z" # "2020-04-24T19:16:49.393376+00:00Z"

  json_query = "payload"

  # json_name_key = "body_name"
  json_name_key = "name"
  data_format = "json"